# Jarvis AI - Voice-Controlled AI Assistant

## ğŸ¥ Project Demonstration

[**Watch the project demonstration video here**](https://youtu.be/UScktVhRJ8Y)

> Replace `YOUR_VIDEO_LINK_HERE` with your actual video URL

---

## ğŸ” Face Recognition System

The `face_rec/` folder contains a comprehensive face recognition implementation:

- **ğŸ““ Training Notebook** - Complete dataset training pipeline with **92% accuracy**
- **ğŸ—œï¸ Model Weights** - Pre-trained model weights stored in zip file format
- **ğŸ¯ Recognition Engine** - Real-time face detection and recognition capabilities

This component can be integrated with the main Jarvis AI system for personalized user interactions and enhanced security features.

## ğŸ¤– Open Source AI Components

Jarvis AI is built entirely on **open source technologies**:

- **ğŸ§  Large Language Models (LLMs)** - Utilizes open source models via OpenRouter API
  - Supports various open source models (Mistral, etc.)
  - No dependency on proprietary AI services

- **ğŸ—£ï¸ Text-to-Speech** - **Kokoro TTS** for natural voice synthesis
  - High-quality, open source TTS engine
  - Customizable voice characteristics
  - Local processing for privacy

---

## ğŸ“‹ Overview

Jarvis AI is a modular voice-controlled AI assistant designed to interpret and execute user commands through natural voice interaction. The system provides hands-free control of various functions and features an extensible architecture for adding new capabilities.

## âœ¨ Key Features

- ğŸ¤ **Voice Input Processing** - Real-time speech recognition and processing
- ğŸ—£ï¸ **Text-to-Speech Output** - Natural voice responses using TTS
- ğŸ¯ **Wake Word Activation** - Responds to "Sarah" and variations
- ğŸ§  **Command Routing** - Intelligent command parsing and execution
- ğŸ”§ **Modular Skills System** - Easy to extend with new capabilities
- ğŸ’¬ **Conversational AI** - Context-aware conversations with LLM integration

## ğŸ—ï¸ Project Structure

```
jarvis_ai/
â”œâ”€â”€ ğŸ“ core/                    # Core engine components
â”‚   â”œâ”€â”€ command_router.py       # Routes commands to skills
â”‚   â”œâ”€â”€ conversation.py         # Handles AI conversations
â”‚   â”œâ”€â”€ openrouter_client.py    # LLM API client
â”‚   â”œâ”€â”€ tts.py                  # Text-to-speech synthesis
â”‚   â”œâ”€â”€ voice_input.py          # Voice input processing
â”‚   â””â”€â”€ wake_word_listener.py   # Wake word detection
â”‚
â”œâ”€â”€ ğŸ“ skills/                  # Pluggable skill modules
â”‚   â”œâ”€â”€ ğŸ“ general/
â”‚   â”‚   â””â”€â”€ hello_skill.py      # Basic greeting responses
â”‚   â”œâ”€â”€ ğŸ“ system/
â”‚   â”‚   â””â”€â”€ app_launcher.py     # Application launching
â”‚   â”œâ”€â”€ browser_skill.py        # Web browser automation
â”‚   â”œâ”€â”€ email_skill.py          # Email operations
â”‚   â”œâ”€â”€ read_screen.py          # Screen reading & OCR
â”‚   â”œâ”€â”€ weather_skill.py        # Weather information
â”‚   â””â”€â”€ whatsapp_skill.py       # WhatsApp messaging
â”‚
â”œâ”€â”€ ğŸ“ assets/                  # Static resources
â”‚   â”œâ”€â”€ ğŸ“ apps/               # Application mappings
â”‚   â””â”€â”€ ğŸ“ llms/               # LLM test scripts
â”‚
â”œâ”€â”€ ğŸ“ tests/                   # Test suites
â”‚   â”œâ”€â”€ ğŸ“ skills/             # Skill-specific tests
â”‚   â”œâ”€â”€ ğŸ“ stt/                # Speech-to-text tests
â”‚   â””â”€â”€ ğŸ“ tts/                # Text-to-speech tests
â”‚
â”œâ”€â”€ main.py                     # Application entry point
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- Microphone access
- Speaker/headphone output

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd jarvis_ai
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables** (optional)
   Create a `.env` file with your API keys:
   ```env
   OPENROUTER_API_KEY=your_openrouter_key
   OPENWEATHER_API_KEY=your_weather_key
   EMAIL_ADDRESS=your_email@example.com
   EMAIL_PASSWORD=your_app_password
   ```

### Running the Application

**Normal Mode:**
```bash
python main.py
```

**Silent Mode:**
```bash
python main.py --silent
```

In silent mode, the assistant runs quietly in the background and only responds when the wake word "Sarah" is detected.

## ğŸ¯ Core Components

### 1. **Wake Word Listener** (`core/wake_word_listener.py`)
- Continuously monitors audio input for the wake word "Sarah"
- Supports variations: sara, sarra, sahra, sahara, sari, sarae
- Activates the system when wake word is detected

### 2. **Voice Input Processing** (`core/voice_input.py`)
- Captures audio from microphone
- Converts speech to text using speech recognition
- Handles audio preprocessing and noise reduction

### 3. **Command Router** (`core/command_router.py`)
- Analyzes user input to determine intent
- Routes commands to appropriate skill modules
- Manages the flow between different system components

### 4. **Conversation System** (`core/conversation.py`)
- Handles AI-powered conversations
- Integrates with LLM APIs for natural language understanding
- Maintains context across interactions

### 5. **Text-to-Speech** (`core/tts.py`)
- Converts text responses to natural speech
- Provides audio feedback to users
- Configurable voice settings

## ğŸ› ï¸ Available Skills

### System Skills
- **App Launcher** - Launch applications by voice command
- **Browser Control** - Automate web browser tasks

### Communication Skills
- **Email Management** - Send and read emails
- **WhatsApp Messaging** - Send WhatsApp messages

### Information Skills
- **Weather Reports** - Get current weather and forecasts
- **Screen Reading** - Read and analyze screen content with OCR

### General Skills
- **Greetings** - Responds to hello and greeting commands
- **Conversations** - General AI-powered conversations

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENROUTER_API_KEY` | API key for LLM services | Optional |
| `OPENWEATHER_API_KEY` | OpenWeatherMap API key | For weather |
| `WEATHERAPI_KEY` | WeatherAPI key | For weather |
| `EMAIL_ADDRESS` | Email account | For email skills |
| `EMAIL_PASSWORD` | Email app password | For email skills |
| `WHATSAPP_API_KEY` | WhatsApp Python Library | For WhatsApp |
| `DEFAULT_LOCATION` | Default weather location | Optional |

### Application Settings
- Wake word sensitivity can be adjusted in `wake_word_listener.py`
- TTS voice and speed settings in `tts.py`
- Skill registration and routing in `command_router.py`

## ğŸ§ª Testing

Run the test suite:
```bash
python -m pytest tests/
```

Run specific test categories:
```bash
# Test skills
python -m pytest tests/skills/

# Test TTS functionality
python -m pytest tests/tts/

# Test speech-to-text
python -m pytest tests/stt/
```

## ğŸ”Œ Extending the System

### Adding New Skills

1. Create a new skill file in the `skills/` directory
2. Implement the required functions for your skill
3. Follow the existing skill patterns for consistency
4. Add command routing logic in `command_router.py`

### Skill Development Guidelines

- Each skill should be self-contained
- Include proper error handling and logging
- Add type hints and documentation
- Write corresponding tests

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“ License

[Add your license information here]

## ğŸ†˜ Troubleshooting

### Common Issues

**Microphone not working:**
- Check microphone permissions
- Verify audio input device in system settings

**Wake word not detected:**
- Ensure clear pronunciation of "Sarah"
- Check microphone sensitivity settings
- Test in a quiet environment

**API errors:**
- Verify API keys are correctly set in environment variables
- Check internet connection for external API calls

**Module import errors:**
- Ensure all dependencies are installed: `pip install -r requirements.txt`
- Check Python version compatibility

## ğŸ“ Support

For issues and questions:
- Create an issue in the repository
- Check the troubleshooting section above
- Review the test files for usage examples

---

**Built with â¤ï¸ for voice-controlled automation**