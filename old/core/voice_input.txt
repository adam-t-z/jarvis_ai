# core/voice_input.py

import sounddevice as sd
from scipy.io.wavfile import write
import tempfile
import os

from faster_whisper import WhisperModel
from core.tts import speak

# Load model once
model = WhisperModel("base", device="cpu", compute_type="int16")  # change to "cuda" if using GPU

def listen():
    fs = 16000  # Sample rate
    duration = 5  # seconds
    print("üé§ Listening...")

    try:
        # Record audio
        audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
        sd.wait()

        # Save to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
            write(tmpfile.name, fs, audio)
            audio_path = tmpfile.name

        print("Transcribing...")
        segments, info = model.transcribe(audio_path)

        text = ""
        for segment in segments:
            text += segment.text + " "

        text = text.strip()
        print(f"üó£Ô∏è You said: {text}")

        # Delete temp file
        os.remove(audio_path)

        return text.lower()

    except Exception as e:
        speak("Something went wrong while listening.")
        print(f"Listen error: {e}")
        return ""
